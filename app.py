import streamlit as st
import streamlit.components.v1 as components
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import time
import subprocess
import os
import requests
from io import BytesIO

# Word/PDFä½œæˆç”¨
from docx import Document
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import mm
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_JUSTIFY

# ==========================================
# è¨­å®šï¼šå…¥ã‚Šå£URL
# ==========================================
FIXED_ENTRY_URL = "https://www.h-ken.net/mypage/20250611_1605697556/"

# ==========================================
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
# ==========================================
def install_playwright():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Install error: {e}")

if "setup_done" not in st.session_state:
    with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
        install_playwright()
        st.session_state.setup_done = True

# ==========================================
# ã€é‡è¦ã€‘æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç¢ºä¿ï¼ˆå³å¯†ãªãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
# ==========================================
def get_valid_japanese_font():
    font_filename = "IPAexGothic.ttf"
    # å®‰å®šã—ãŸGitHubã®Raw URL
    font_url = "https://raw.githubusercontent.com/minoryorg/ipaex-font/master/ipaexg.ttf"
    
    # 1. æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ï¼ˆå£Šã‚Œã¦ã„ãŸã‚‰æ¶ˆã™ï¼‰
    if os.path.exists(font_filename):
        # ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ç´„4MBä»¥ä¸Šã‚ã‚‹ã¯ãšã€‚2MBä»¥ä¸‹ãªã‚‰å£Šã‚Œã¦ã„ã‚‹ã¨ã¿ãªã™
        if os.path.getsize(font_filename) < 2 * 1024 * 1024:
            os.remove(font_filename)

    # 2. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆï¼‰
    if not os.path.exists(font_filename):
        try:
            response = requests.get(font_url, timeout=60)
            if response.status_code == 200:
                with open(font_filename, "wb") as f:
                    f.write(response.content)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç›´å¾Œã«ã‚‚ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                if os.path.getsize(font_filename) < 2 * 1024 * 1024:
                    os.remove(font_filename) # å¤±æ•—ã—ãŸã®ã§æ¶ˆã™
                    return None
            else:
                return None
        except Exception:
            return None
            
    return font_filename if os.path.exists(font_filename) else None

# ==========================================
# Wordãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
# ==========================================
def create_docx(title, clean_text_list):
    doc = Document()
    doc.add_heading(title, 0)
    
    for text in clean_text_list:
        if text.strip():
            doc.add_paragraph(text)
            
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# PDFãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
# ==========================================
def create_pdf(title, clean_text_list):
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4,
                            rightMargin=20*mm, leftMargin=20*mm,
                            topMargin=20*mm, bottomMargin=20*mm)
    
    # ãƒ•ã‚©ãƒ³ãƒˆæº–å‚™
    font_path = get_valid_japanese_font()
    
    # ãƒ•ã‚©ãƒ³ãƒˆãŒç¢ºä¿ã§ããŸå ´åˆã®ã¿ç™»éŒ²
    if font_path:
        try:
            pdfmetrics.registerFont(TTFont('Japanese', font_path))
            font_name = 'Japanese'
        except Exception:
            # ç™»éŒ²ã«å¤±æ•—ã—ãŸã‚‰è‹±èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆæ–‡å­—åŒ–ã‘ã™ã‚‹ãŒã‚¨ãƒ©ãƒ¼ã§è½ã¡ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼‰
            font_name = 'Helvetica'
    else:
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚
        font_name = 'Helvetica'

    styles = getSampleStyleSheet()
    
    # æ—¥æœ¬èªå¯¾å¿œã‚¹ã‚¿ã‚¤ãƒ«
    style_body = ParagraphStyle(name='JapaneseBody',
                                parent=styles['Normal'],
                                fontName=font_name,
                                fontSize=10.5,
                                leading=16,
                                spaceAfter=6,
                                alignment=TA_JUSTIFY)
                                
    style_title = ParagraphStyle(name='JapaneseTitle',
                                 parent=styles['Heading1'],
                                 fontName=font_name,
                                 fontSize=16,
                                 leading=20,
                                 spaceAfter=20)

    story = []
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    story.append(Paragraph(title, style_title))
    
    # æœ¬æ–‡
    for text in clean_text_list:
        if text.strip():
            # ç‰¹æ®Šæ–‡å­—ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            safe_text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            story.append(Paragraph(safe_text, style_body))
            story.append(Spacer(1, 2*mm))

    try:
        doc.build(story)
        buffer.seek(0)
        return buffer, True # æˆåŠŸãƒ•ãƒ©ã‚°
    except Exception:
        return None, False

# ==========================================
# ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œï¼ˆJSã§ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ç ´å£Šï¼‰
# ==========================================
def fetch_html_force_clean(target_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        iphone_12 = p.devices['iPhone 12']
        context = browser.new_context(**iphone_12)
        page = context.new_page()

        try:
            page.goto(FIXED_ENTRY_URL, timeout=30000)
            time.sleep(2) 
            page.goto(target_url, timeout=30000)
            page.wait_for_load_state("domcontentloaded")
            time.sleep(2) 

            # ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ç ´å£Š
            page.evaluate("""
                () => {
                    const keywords = ['ã¯ã„', 'YES', 'Yes', '18æ­³', 'Enter', 'å…¥ã‚Šå£', 'å…¥å ´'];
                    const buttons = document.querySelectorAll('a, button, div, span');
                    for (let btn of buttons) {
                        if (keywords.some(k => btn.innerText && btn.innerText.includes(k))) {
                            btn.click();
                        }
                    }
                    const allDivs = document.querySelectorAll('body > div, body > section');
                    allDivs.forEach(div => {
                        const style = window.getComputedStyle(div);
                        if (style.position === 'fixed' && style.zIndex > 50) {
                            div.remove();
                        }
                    });
                    document.body.style.overflow = 'visible';
                    document.body.style.height = 'auto';
                }
            """)
            time.sleep(1) 
            return page.content()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            browser.close()

# ==========================================
# æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def extract_target_content(html_content, target_url):
    soup = BeautifulSoup(html_content, 'html.parser')

    styles = []
    for link in soup.find_all('link', rel='stylesheet'):
        styles.append(str(link))
    for style in soup.find_all('style'):
        styles.append(str(style))
    style_html = "\n".join(styles)

    # ã‚¿ã‚¤ãƒˆãƒ«
    title_html = ""
    title_text_clean = "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"
    target_h1 = soup.find("h1", class_="pageTitle")
    
    if target_h1:
        title_html = str(target_h1)
        title_text_clean = target_h1.get_text(strip=True)
    else:
        target_h1 = soup.find("h1")
        if target_h1:
            title_html = str(target_h1)
            title_text_clean = target_h1.get_text(strip=True)

    simple_title_text = soup.title.get_text(strip=True) if soup.title else "æŠ½å‡ºçµæœ"

    # æœ¬æ–‡
    body_html = "<div>æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>"
    text_list_for_file = []
    
    target_div = soup.find(id="sentenceBox")
    if not target_div:
        target_div = soup.find(id="main_txt")

    if target_div:
        for bad in target_div.find_all(["script", "noscript", "iframe", "form", "button", "input"]):
            bad.decompose()

        cut_point = target_div.find(class_="kakomiPop2")
        if cut_point:
            for sibling in cut_point.find_next_siblings():
                sibling.decompose()
            cut_point.decompose()

        body_html = str(target_div)
        
        for elem in target_div.find_all(['p', 'div', 'h2', 'h3', 'br']):
            txt = elem.get_text(strip=True)
            if txt:
                text_list_for_file.append(txt)

    final_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <base href="{target_url}">
        {style_html}
        <style>
            body {{
                background-color: #fff;
                padding: 15px;
                font-family: sans-serif;
                overflow: auto !important;
            }}
            h1.pageTitle {{
                font-size: 20px;
                margin-bottom: 20px;
                border-bottom: 1px solid #ccc;
                padding-bottom: 10px;
                line-height: 1.4;
            }}
            #sentenceBox {{
                font-size: 16px;
                line-height: 1.8;
                color: #333;
            }}
        </style>
    </head>
    <body>
        {title_html}
        {body_html}
    </body>
    </html>
    """

    return simple_title_text, title_text_clean, text_list_for_file, final_html

# ==========================================
# ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="H-Review Pro", layout="centered")

st.title("ğŸ’ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºã‚¢ãƒ—ãƒª")
st.caption("æŠ½å‡ºå¾Œã€ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ä¿å­˜ã§ãã¾ã™ã€‚")

url = st.text_input("èª­ã¿ãŸã„è¨˜äº‹ã®URL", placeholder="https://...")

# å…¨å¹…ãƒœã‚¿ãƒ³
if st.button("æŠ½å‡ºã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status = st.empty()
        status.info("â³ ã‚µã‚¤ãƒˆã‚’è§£æä¸­... (10ã€œ20ç§’ã‹ã‹ã‚Šã¾ã™)")
        
        html = fetch_html_force_clean(url)

        if html:
            status.info("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            
            page_title, article_title, text_list, final_html = extract_target_content(html, url)
            
            # --- å‡¦ç†å®Œäº† ---
            status.empty()
            st.success("æŠ½å‡ºå®Œäº†ï¼")
            
            # === ä¿å­˜ãƒœã‚¿ãƒ³ã‚¨ãƒªã‚¢ (ãƒ¡ã‚¤ãƒ³ç”»é¢ãƒ»æ¨ªä¸¦ã³) ===
            col1, col2 = st.columns(2)
            
            with col1:
                # Word
                docx_file = create_docx(article_title, text_list)
                st.download_button(
                    label="ğŸ“„ Wordã§ä¿å­˜",
                    data=docx_file,
                    file_name="story.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    use_container_width=True # ã‚¹ãƒãƒ›ã§è¦‹ã‚„ã™ãå¹…ä¸€æ¯ã«
                )
            
            with col2:
                # PDF
                pdf_file, pdf_success = create_pdf(article_title, text_list)
                if pdf_success:
                    st.download_button(
                        label="ğŸ“• PDFã§ä¿å­˜",
                        data=pdf_file,
                        file_name="story.pdf",
                        mime="application/pdf",
                        use_container_width=True # ã‚¹ãƒãƒ›ã§è¦‹ã‚„ã™ãå¹…ä¸€æ¯ã«
                    )
                else:
                    st.error("PDFç”¨ãƒ•ã‚©ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼")
            
            st.divider()
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            components.html(final_html, height=800, scrolling=True)
            
        else:
            status.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
