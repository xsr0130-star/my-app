import streamlit as st
import streamlit.components.v1 as components
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup, NavigableString, Tag, Comment
import time
import subprocess
import os
import re
from io import BytesIO

# Wordä½œæˆç”¨
from docx import Document
from docx.shared import RGBColor, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH

# ==========================================
# è¨­å®š
# ==========================================
FIXED_ENTRY_URL = "https://www.h-ken.net/mypage/20250611_1605697556/"

# ==========================================
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
# ==========================================
def install_playwright():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Install error: {e}")

if "setup_done" not in st.session_state:
    with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
        install_playwright()
        st.session_state.setup_done = True

# ==========================================
# ä¾¿åˆ©é–¢æ•°ï¼šãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ==========================================
def sanitize_filename(text):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’å‰Šé™¤"""
    if not text:
        return "story"
    # ç¦æ­¢æ–‡å­—ã‚’å…¨è§’ãªã©ã«ç½®æ›ã™ã‚‹ã‹å‰Šé™¤
    text = re.sub(r'[\\/*?:"<>|]', "", text)
    text = text.replace('\n', '').replace('\r', '').replace('\t', '')
    text = text.strip()
    if len(text) > 60: # é•·ã™ãã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§ã‚«ãƒƒãƒˆ
        text = text[:60]
    return text if text else "story"

# ==========================================
# è‰²è§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶è¨ˆç®—å€¤åˆ©ç”¨ï¼‰
# ==========================================
def get_rgb_from_str(color_str):
    if not color_str: return None
    c = color_str.lower().strip()
    
    # rgba(...)
    rgb_match = re.search(r'rgba?\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)', c)
    if rgb_match:
        return RGBColor(int(rgb_match.group(1)), int(rgb_match.group(2)), int(rgb_match.group(3)))

    # Hex
    hex_match = re.search(r'#([0-9a-f]{6})', c)
    if hex_match:
        h = hex_match.group(1)
        return RGBColor(int(h[:2], 16), int(h[2:4], 16), int(h[4:], 16))
    
    # åŸºæœ¬ãƒãƒƒãƒ—
    colors = {
        'red': RGBColor(255, 0, 0), 'blue': RGBColor(0, 0, 255), 'green': RGBColor(0, 128, 0),
        'black': RGBColor(0, 0, 0), 'white': RGBColor(255, 255, 255),
        'orange': RGBColor(255, 165, 0), 'pink': RGBColor(255, 192, 203),
        'purple': RGBColor(128, 0, 128), 'gold': RGBColor(255, 215, 0)
    }
    return colors.get(c.split()[0])

def apply_style_to_run(run, element):
    """ãƒ‡ãƒ¼ã‚¿å±æ€§(data-calc-color)ã‚’è¦‹ã¦ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨"""
    calc_color = element.get('data-calc-color')
    calc_bold = element.get('data-calc-bold')
    
    if calc_bold == 'true':
        run.bold = True
    elif element.name in ['b', 'strong', 'h1', 'h2']:
        run.bold = True
        
    if calc_color:
        rgb = get_rgb_from_str(calc_color)
        if rgb:
            run.font.color.rgb = rgb
            return

    style_attr = element.get('style', '').lower()
    if 'color' in style_attr:
        m = re.search(r'color\s*:\s*([^;"]+)', style_attr)
        if m: 
            rgb = get_rgb_from_str(m.group(1))
            if rgb: run.font.color.rgb = rgb

# ==========================================
# Wordä½œæˆã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆç©ºç™½è¡Œå¯¾å¿œç‰ˆï¼‰
# ==========================================
BLOCK_TAGS = ['p', 'div', 'h1', 'h2', 'h3', 'blockquote', 'li', 'article', 'section']

def process_node_recursive(paragraph, node):
    if isinstance(node, NavigableString):
        text = str(node)
        # æœ¬æ–‡ä»¥å¤–ã®ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å¤–
        if "contents_within" not in text:
            # ç©ºç™½ã ã‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã€æ”¹è¡Œã®æ„å‘³ã‚’æŒã¤ã“ã¨ãŒã‚ã‚‹ã®ã§å®Œå…¨ç„¡è¦–ã¯ã—ãªã„
            # ãŸã ã—Wordã§ã¯é€£ç¶šã™ã‚‹ç©ºç™½ã¯ç„¡è¦–ã•ã‚Œã‚‹ãŸã‚ã€æ„å‘³ã®ã‚ã‚‹æ–‡å­—ãŒã‚ã‚‹ã‹ç¢ºèª
            if text.strip():
                run = paragraph.add_run(text)
                if node.parent:
                    apply_style_to_run(run, node.parent)
                
    elif isinstance(node, Tag):
        if node.name == 'br':
            # <br> ã¯ç¢ºå®Ÿã«æ”¹è¡Œã•ã›ã‚‹
            paragraph.add_run('\n')
        elif node.name in ['script', 'style', 'noscript']:
            pass
        else:
            # å­è¦ç´ ã‚’å‡¦ç†
            for child in node.children:
                process_node_recursive(paragraph, child)
            
            # ãƒ–ãƒ­ãƒƒã‚¯è¦ç´ ãŒçµ‚ã‚ã£ãŸã‚‰æ”¹è¡Œã‚’å…¥ã‚Œã‚‹
            # ã“ã‚Œã«ã‚ˆã‚Š <p>ã‚</p><p>ã„</p> ãŒãã£ã¤ã‹ãšã«æ”¹è¡Œã•ã‚Œã‚‹
            if node.name in BLOCK_TAGS:
                paragraph.add_run('\n')

def create_rich_docx(title_html, body_html):
    doc = Document()
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    soup_title = BeautifulSoup(title_html, 'html.parser')
    p_title = doc.add_paragraph()
    p_title.alignment = WD_ALIGN_PARAGRAPH.LEFT
    process_node_recursive(p_title, soup_title)
    
    for run in p_title.runs:
        run.font.size = Pt(16)
        if not run.bold: run.bold = True

    doc.add_paragraph("") 

    # æœ¬æ–‡
    soup_body = BeautifulSoup(body_html, 'html.parser')
    
    # ãƒ«ãƒ¼ãƒˆç›´ä¸‹ã®è¦ç´ ã”ã¨ã«æ®µè½ã‚’ä½œæˆã™ã‚‹æ–¹å¼ã«å¤‰æ›´
    # ã“ã‚Œã«ã‚ˆã‚Šã€å¤§ããªãƒ–ãƒ­ãƒƒã‚¯é–“ã®ä½™ç™½ãŒè‡ªç„¶ã«ãªã‚‹
    top_level_elements = soup_body.find_all(True, recursive=False)
    
    if not top_level_elements:
        # è¦ç´ ãŒãªã„ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç›´æ›¸ããªã©ï¼‰å ´åˆã¯1ã¤ã®æ®µè½ã§
        p = doc.add_paragraph()
        process_node_recursive(p, soup_body)
    else:
        for element in top_level_elements:
            p = doc.add_paragraph()
            # è¡Œé–“ã‚’å°‘ã—è©°ã‚ãŸã„å ´åˆã¯ã“ã“ã‚’èª¿æ•´ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯åºƒã‚ï¼‰
            # p.paragraph_format.space_after = Pt(0) 
            
            process_node_recursive(p, element)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œ
# ==========================================
def fetch_html_force_clean(target_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        iphone_12 = p.devices['iPhone 12']
        context = browser.new_context(**iphone_12)
        page = context.new_page()

        try:
            page.goto(FIXED_ENTRY_URL, timeout=30000)
            time.sleep(2) 
            page.goto(target_url, timeout=30000)
            page.wait_for_load_state("domcontentloaded")
            time.sleep(2) 

            page.evaluate("""
                () => {
                    // ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ç ´å£Š
                    const keywords = ['ã¯ã„', 'YES', 'Yes', '18æ­³', 'Enter', 'å…¥ã‚Šå£', 'å…¥å ´'];
                    const buttons = document.querySelectorAll('a, button, div, span');
                    for (let btn of buttons) {
                        if (keywords.some(k => btn.innerText && btn.innerText.includes(k))) {
                            btn.click();
                        }
                    }
                    const allDivs = document.querySelectorAll('body > div, body > section');
                    allDivs.forEach(div => {
                        const style = window.getComputedStyle(div);
                        if (style.position === 'fixed' && style.zIndex > 50) {
                            div.remove();
                        }
                    });
                    document.body.style.overflow = 'visible';
                    document.body.style.height = 'auto';
                    
                    // è‰²æƒ…å ±ç„¼ãä»˜ã‘
                    const targetArea = document.getElementById('sentenceBox') || document.body;
                    const allElements = targetArea.querySelectorAll('*');
                    allElements.forEach(el => {
                        const style = window.getComputedStyle(el);
                        const color = style.color;
                        const weight = style.fontWeight;
                        if (color && color !== 'rgb(0, 0, 0)') {
                            el.setAttribute('data-calc-color', color);
                        }
                        if (weight === 'bold' || parseInt(weight) >= 700) {
                            el.setAttribute('data-calc-bold', 'true');
                        }
                    });
                }
            """)
            time.sleep(1) 
            return page.content()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            browser.close()

# ==========================================
# æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def extract_target_content(html_content, target_url):
    soup = BeautifulSoup(html_content, 'html.parser')

    styles = []
    for link in soup.find_all('link', rel='stylesheet'):
        styles.append(str(link))
    for style in soup.find_all('style'):
        styles.append(str(style))
    style_html = "\n".join(styles)

    # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
    title_html = ""
    title_text_clean = "ç„¡é¡Œ"
    
    target_h1 = soup.find("h1", class_="pageTitle")
    if target_h1:
        title_html = str(target_h1)
        title_text_clean = target_h1.get_text(strip=True)
    else:
        target_h1 = soup.find("h1")
        if target_h1:
            title_html = str(target_h1)
            title_text_clean = target_h1.get_text(strip=True)
    
    if title_text_clean == "ç„¡é¡Œ" and soup.title:
        title_text_clean = soup.title.get_text(strip=True)

    body_html = "<div>æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>"
    target_div = soup.find(id="sentenceBox")
    if not target_div:
        target_div = soup.find(id="main_txt")

    if target_div:
        for comment in target_div.find_all(string=lambda text: isinstance(text, Comment)):
            comment.extract()
        for bad in target_div.find_all(["script", "noscript", "iframe", "form", "button", "input"]):
            bad.decompose()
        cut_point = target_div.find(class_="kakomiPop2")
        if cut_point:
            for sibling in cut_point.find_next_siblings():
                sibling.decompose()
            cut_point.decompose()
        bad_words = ["ç„¡æ–­è»¢è¼‰", "Googleã«é€šå ±", "åˆ‘äº‹å‘Šè¨´", "æ°‘äº‹è¨´è¨Ÿ", "ã‚¨ãƒã‚±ãƒ³", "contents_within"]
        for tag in target_div.find_all(['p', 'div', 'span', 'font', 'b']):
            text = tag.get_text()
            if any(w in text for w in bad_words):
                if len(text) < 400:
                    tag.decompose()
        body_html = str(target_div)

    final_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <base href="{target_url}">
        {style_html}
        <style>
            body {{ background-color: #fff; padding: 15px; font-family: sans-serif; overflow: auto !important; }}
            h1.pageTitle {{ font-size: 20px; margin-bottom: 20px; border-bottom: 1px solid #ccc; padding-bottom: 10px; line-height: 1.4; }}
            #sentenceBox {{ font-size: 16px; line-height: 1.8; color: #333; }}
        </style>
    </head>
    <body>
        {title_html}
        {body_html}
    </body>
    </html>
    """

    return title_html, body_html, final_html, title_text_clean

# ==========================================
# ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="H-Review Ultra", layout="centered")

st.title("ğŸ’ ç©¶æ¥µç‰ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º")
st.caption("å…¨è‰²å¯¾å¿œãƒ»ç©ºç™½è¡Œç¶­æŒãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åè‡ªå‹•åŒ–")

url = st.text_input("èª­ã¿ãŸã„è¨˜äº‹ã®URL", placeholder="https://...")

if st.button("æŠ½å‡ºã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status = st.empty()
        status.info("â³ è§£æä¸­...")
        
        html = fetch_html_force_clean(url)

        if html:
            status.info("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            
            title_html_str, body_html_str, final_html_preview, title_text_clean = extract_target_content(html, url)
            
            status.empty()
            st.success("å®Œäº†ï¼")
            
            # Wordä½œæˆ
            docx_file = create_rich_docx(title_html_str, body_html_str)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
            safe_filename = sanitize_filename(title_text_clean) + ".docx"
            
            st.download_button(
                label=f"ğŸ“˜ ã€Œ{safe_filename}ã€ã§ä¿å­˜",
                data=docx_file,
                file_name=safe_filename,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True
            )
            
            st.divider()
            components.html(final_html_preview, height=800, scrolling=True)
            
        else:
            status.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
