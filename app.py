import streamlit as st
import streamlit.components.v1 as components
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import time
import subprocess

# ==========================================
# è¨­å®šï¼šå…¥ã‚Šå£URLï¼ˆã“ã“ã‚’è¸ã‚“ã§ã‹ã‚‰è¡Œãï¼‰
# ==========================================
FIXED_ENTRY_URL = "https://www.h-ken.net/mypage/20250611_1605697556/"

# ==========================================
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
# ==========================================
def install_playwright():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Install error: {e}")

if "setup_done" not in st.session_state:
    with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
        install_playwright()
        st.session_state.setup_done = True

# ==========================================
# ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œ
# ==========================================
def fetch_html_via_route(target_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        iphone_12 = p.devices['iPhone 12']
        context = browser.new_context(**iphone_12)
        page = context.new_page()

        try:
            # 1. å…¥ã‚Šå£URLã¸
            page.goto(FIXED_ENTRY_URL, timeout=30000)
            time.sleep(2) 

            # 2. ç›®çš„ã®URLã¸
            page.goto(target_url, timeout=30000)
            page.wait_for_load_state("networkidle")

            return page.content()

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            browser.close()

# ==========================================
# æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¤–ç§‘æ‰‹è¡“æ–¹å¼ï¼‰
# ==========================================
def extract_only_content_keep_css(html_content, target_url):
    soup = BeautifulSoup(html_content, 'html.parser')

    # 1. CSSï¼ˆãƒ‡ã‚¶ã‚¤ãƒ³ï¼‰ã ã‘ã¯å…ˆã«ç¢ºä¿ã™ã‚‹
    styles = []
    # å¤–éƒ¨CSSãƒ•ã‚¡ã‚¤ãƒ«
    for link in soup.find_all('link', rel='stylesheet'):
        styles.append(str(link))
    # ãƒšãƒ¼ã‚¸å†…ã®CSS
    for style in soup.find_all('style'):
        styles.append(str(style))
    
    style_html = "\n".join(styles)

    # 2. æœ¬æ–‡ãŒå…¥ã£ã¦ã„ã‚‹ã€Œãƒ¡ã‚¤ãƒ³ã®ç®±ã€ã ã‘ã‚’æ¢ã—å‡ºã™
    # ï¼ˆç”»é¢å…¨ä½“ soup ã‚’ä½¿ã†ã¨ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚‚æ®‹ã‚‹ã®ã§ã€ä¸­èº«ã ã‘å–ã‚Šå‡ºã™ï¼‰
    
    max_score = 0
    best_html = "<div>æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>"
    
    # å€™è£œã¨ãªã‚‹ã‚¿ã‚°ï¼ˆdiv, section, article, mainï¼‰
    candidates = soup.find_all(['div', 'article', 'section', 'main', 'td'])

    for candidate in candidates:
        # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæ–‡å­—æ•°ãŒå¤šã„å ´æ‰€ï¼æœ¬æ–‡ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼‰
        text = candidate.get_text(strip=True)
        score = len(text)
        
        # ãƒªãƒ³ã‚¯ã ã‚‰ã‘ã®å ´æ‰€ï¼ˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼‰ã¯é™¤å¤–
        links = candidate.find_all('a')
        link_len = sum([len(a.get_text()) for a in links])
        
        if score > 200: # ã‚ã‚‹ç¨‹åº¦é•·ã„ãƒ–ãƒ­ãƒƒã‚¯ã®ã¿å¯¾è±¡
            if (link_len / score) < 0.5: # ãƒªãƒ³ã‚¯æ–‡å­—ç‡ãŒåŠåˆ†ä»¥ä¸‹
                if score > max_score:
                    max_score = score
                    # ã“ã“ã§ .decompose() ã‚’ä½¿ã£ã¦ã€ã“ã®å€™è£œã®ä¸­ã«ã‚ã‚‹é‚ªé­”ãªã‚¿ã‚°ã ã‘æ¶ˆã™
                    # scriptï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼‰ã¯çµ¶å¯¾ã«æ¶ˆã™ï¼ã“ã‚ŒãŒãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã®æ­£ä½“
                    for bad in candidate.find_all(["script", "noscript", "iframe", "form", "button", "input"]):
                        bad.decompose()
                    
                    # å€™è£œã‚’HTMLã¨ã—ã¦ä¿å­˜
                    best_html = str(candidate)

    # 3. æ–°ã—ã„ãã‚Œã„ãªHTMLã‚’çµ„ã¿ç«‹ã¦ã‚‹
    # ç¢ºä¿ã—ã¦ãŠã„ãŸCSS ï¼‹ åˆ‡ã‚ŠæŠœã„ãŸæœ¬æ–‡ ï¼ å®Œæˆ
    final_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <base href="{target_url}"> <!-- CSSã®ãƒªãƒ³ã‚¯åˆ‡ã‚Œé˜²æ­¢ -->
        {style_html}
        <style>
            body {{
                background-color: #fff;
                padding: 10px;
                font-family: sans-serif;
                overflow: auto !important; /* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¨±å¯ */
            }}
            img {{ display: none !important; }} /* ç”»åƒã¯éè¡¨ç¤º */
            /* å¿µã®ãŸã‚å›ºå®šé…ç½®ã‚’ç„¡åŠ¹åŒ–ã™ã‚‹CSSã‚‚å…¥ã‚Œã¦ãŠã */
            div {{ position: static !important; }}
        </style>
    </head>
    <body>
        {best_html}
    </body>
    </html>
    """

    # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
    title_text = "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"
    if soup.title:
        title_text = soup.title.get_text(strip=True)

    return title_text, final_html

# ==========================================
# ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="H-Review Final", layout="centered")
st.title("ğŸ’ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºãƒªãƒ¼ãƒ€ãƒ¼")
st.caption("ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã®å¤–å´ã‚’åˆ‡ã‚Šæ¨ã¦ã€ä¸­èº«ã ã‘ã‚’è‰²ä»˜ãã§è¡¨ç¤ºã—ã¾ã™ã€‚")

url = st.text_input("èª­ã¿ãŸã„è¨˜äº‹ã®URL", placeholder="https://...")

if st.button("æŠ½å‡ºã™ã‚‹"):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status = st.empty()
        status.text("èª­ã¿è¾¼ã¿ä¸­...")
        
        html = fetch_html_via_route(url)

        if html:
            status.text("æœ¬æ–‡ã‚’åˆ‡ã‚ŠæŠœãä¸­...")
            title, final_html = extract_only_content_keep_css(html, url)
            status.empty()
            
            st.success("å®Œäº†")
            st.subheader(title)
            
            # iframeã§è¡¨ç¤º
            components.html(final_html, height=800, scrolling=True)
            
        else:
            status.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
