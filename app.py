import streamlit as st
import streamlit.components.v1 as components
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import time
import subprocess
import os
import requests
from io import BytesIO

# Word/PDFä½œæˆç”¨
from docx import Document
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import mm
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_JUSTIFY

# ==========================================
# è¨­å®šï¼šå…¥ã‚Šå£URL
# ==========================================
FIXED_ENTRY_URL = "https://www.h-ken.net/mypage/20250611_1605697556/"

# ==========================================
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
# ==========================================
def install_playwright():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Install error: {e}")

if "setup_done" not in st.session_state:
    with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
        install_playwright()
        st.session_state.setup_done = True

# ==========================================
# ã€ä¿®æ­£ã€‘æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç¢ºä¿ï¼ˆGoogle Fontsåˆ©ç”¨ï¼‰
# ==========================================
def get_valid_japanese_font():
    # ä»¥å‰ã®å£Šã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤ã™ã‚‹ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼‰
    old_font = "IPAexGothic.ttf"
    if os.path.exists(old_font):
        os.remove(old_font)

    font_filename = "NotoSansJP-Regular.ttf"
    # Google Fontsã®å…¬å¼Rawãƒ‡ãƒ¼ã‚¿ï¼ˆå®‰å®šãƒ»é«˜é€Ÿï¼‰
    font_url = "https://github.com/google/fonts/raw/main/ofl/notosansjp/NotoSansJP-Regular.ttf"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã€ã¾ãŸã¯ã‚µã‚¤ã‚ºãŒãŠã‹ã—ã„å ´åˆã¯å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if not os.path.exists(font_filename) or os.path.getsize(font_filename) < 1000:
        try:
            # ä»¥å‰ã®æ®‹éª¸ã‚’æ¶ˆã™
            if os.path.exists(font_filename):
                os.remove(font_filename)
                
            response = requests.get(font_url, timeout=30)
            if response.status_code == 200:
                with open(font_filename, "wb") as f:
                    f.write(response.content)
            else:
                return None
        except Exception:
            return None
            
    # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ï¼šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã€ã‚µã‚¤ã‚ºãŒååˆ†ã‹
    if os.path.exists(font_filename) and os.path.getsize(font_filename) > 1000000:
        return font_filename
    else:
        return None

# ==========================================
# Wordãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
# ==========================================
def create_docx(title, clean_text_list):
    doc = Document()
    doc.add_heading(title, 0)
    
    for text in clean_text_list:
        if text.strip():
            doc.add_paragraph(text)
            
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# PDFãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
# ==========================================
def create_pdf(title, clean_text_list):
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4,
                            rightMargin=20*mm, leftMargin=20*mm,
                            topMargin=20*mm, bottomMargin=20*mm)
    
    # ãƒ•ã‚©ãƒ³ãƒˆæº–å‚™
    font_path = get_valid_japanese_font()
    font_name = 'Helvetica' # åˆæœŸå€¤ï¼ˆã“ã‚Œã ã¨æ–‡å­—åŒ–ã‘ã™ã‚‹ï¼‰
    
    if font_path:
        try:
            # ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²ã‚’è©¦ã¿ã‚‹
            pdfmetrics.registerFont(TTFont('Japanese', font_path))
            font_name = 'Japanese'
        except Exception as e:
            # ãƒ•ã‚©ãƒ³ãƒˆè‡ªä½“ãŒå£Šã‚Œã¦ã„ã‚‹å ´åˆ
            print(f"Font error: {e}")
            return None, False
    else:
        # ãƒ•ã‚©ãƒ³ãƒˆãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ããªã‹ã£ãŸå ´åˆ
        # å£Šã‚ŒãŸPDFã‚’ä½œã‚‹ãã‚‰ã„ãªã‚‰å¤±æ•—ã¨ã—ã¦è¿”ã™
        return None, False

    styles = getSampleStyleSheet()
    
    # æ—¥æœ¬èªå¯¾å¿œã‚¹ã‚¿ã‚¤ãƒ«
    style_body = ParagraphStyle(name='JapaneseBody',
                                parent=styles['Normal'],
                                fontName=font_name,
                                fontSize=10.5,
                                leading=16,
                                spaceAfter=6,
                                alignment=TA_JUSTIFY)
                                
    style_title = ParagraphStyle(name='JapaneseTitle',
                                 parent=styles['Heading1'],
                                 fontName=font_name,
                                 fontSize=16,
                                 leading=20,
                                 spaceAfter=20)

    story = []
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    story.append(Paragraph(title, style_title))
    
    # æœ¬æ–‡
    for text in clean_text_list:
        if text.strip():
            # ç‰¹æ®Šæ–‡å­—ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            safe_text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            story.append(Paragraph(safe_text, style_body))
            story.append(Spacer(1, 2*mm))

    try:
        doc.build(story)
        buffer.seek(0)
        return buffer, True # æˆåŠŸ
    except Exception:
        return None, False

# ==========================================
# ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œ
# ==========================================
def fetch_html_force_clean(target_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        iphone_12 = p.devices['iPhone 12']
        context = browser.new_context(**iphone_12)
        page = context.new_page()

        try:
            page.goto(FIXED_ENTRY_URL, timeout=30000)
            time.sleep(2) 
            page.goto(target_url, timeout=30000)
            page.wait_for_load_state("domcontentloaded")
            time.sleep(2) 

            # ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ç ´å£Š
            page.evaluate("""
                () => {
                    const keywords = ['ã¯ã„', 'YES', 'Yes', '18æ­³', 'Enter', 'å…¥ã‚Šå£', 'å…¥å ´'];
                    const buttons = document.querySelectorAll('a, button, div, span');
                    for (let btn of buttons) {
                        if (keywords.some(k => btn.innerText && btn.innerText.includes(k))) {
                            btn.click();
                        }
                    }
                    const allDivs = document.querySelectorAll('body > div, body > section');
                    allDivs.forEach(div => {
                        const style = window.getComputedStyle(div);
                        if (style.position === 'fixed' && style.zIndex > 50) {
                            div.remove();
                        }
                    });
                    document.body.style.overflow = 'visible';
                    document.body.style.height = 'auto';
                }
            """)
            time.sleep(1) 
            return page.content()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            browser.close()

# ==========================================
# æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def extract_target_content(html_content, target_url):
    soup = BeautifulSoup(html_content, 'html.parser')

    styles = []
    for link in soup.find_all('link', rel='stylesheet'):
        styles.append(str(link))
    for style in soup.find_all('style'):
        styles.append(str(style))
    style_html = "\n".join(styles)

    # ã‚¿ã‚¤ãƒˆãƒ«
    title_html = ""
    title_text_clean = "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"
    target_h1 = soup.find("h1", class_="pageTitle")
    
    if target_h1:
        title_html = str(target_h1)
        title_text_clean = target_h1.get_text(strip=True)
    else:
        target_h1 = soup.find("h1")
        if target_h1:
            title_html = str(target_h1)
            title_text_clean = target_h1.get_text(strip=True)

    simple_title_text = soup.title.get_text(strip=True) if soup.title else "æŠ½å‡ºçµæœ"

    # æœ¬æ–‡
    body_html = "<div>æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>"
    text_list_for_file = []
    
    target_div = soup.find(id="sentenceBox")
    if not target_div:
        target_div = soup.find(id="main_txt")

    if target_div:
        for bad in target_div.find_all(["script", "noscript", "iframe", "form", "button", "input"]):
            bad.decompose()

        cut_point = target_div.find(class_="kakomiPop2")
        if cut_point:
            for sibling in cut_point.find_next_siblings():
                sibling.decompose()
            cut_point.decompose()

        body_html = str(target_div)
        
        for elem in target_div.find_all(['p', 'div', 'h2', 'h3', 'br']):
            txt = elem.get_text(strip=True)
            if txt:
                text_list_for_file.append(txt)

    final_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <base href="{target_url}">
        {style_html}
        <style>
            body {{
                background-color: #fff;
                padding: 15px;
                font-family: sans-serif;
                overflow: auto !important;
            }}
            h1.pageTitle {{
                font-size: 20px;
                margin-bottom: 20px;
                border-bottom: 1px solid #ccc;
                padding-bottom: 10px;
                line-height: 1.4;
            }}
            #sentenceBox {{
                font-size: 16px;
                line-height: 1.8;
                color: #333;
            }}
        </style>
    </head>
    <body>
        {title_html}
        {body_html}
    </body>
    </html>
    """

    return simple_title_text, title_text_clean, text_list_for_file, final_html

# ==========================================
# ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="H-Review Pro", layout="centered")

st.title("ğŸ’ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºã‚¢ãƒ—ãƒª")
st.caption("æŠ½å‡ºå¾Œã€ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ä¿å­˜ã§ãã¾ã™ã€‚")

url = st.text_input("èª­ã¿ãŸã„è¨˜äº‹ã®URL", placeholder="https://...")

# å…¨å¹…ãƒœã‚¿ãƒ³
if st.button("æŠ½å‡ºã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status = st.empty()
        status.info("â³ ã‚µã‚¤ãƒˆã‚’è§£æä¸­... (10ã€œ20ç§’ã‹ã‹ã‚Šã¾ã™)")
        
        html = fetch_html_force_clean(url)

        if html:
            status.info("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            
            page_title, article_title, text_list, final_html = extract_target_content(html, url)
            
            # --- å‡¦ç†å®Œäº† ---
            status.empty()
            st.success("æŠ½å‡ºå®Œäº†ï¼")
            
            # === ä¿å­˜ãƒœã‚¿ãƒ³ã‚¨ãƒªã‚¢ ===
            col1, col2 = st.columns(2)
            
            with col1:
                # Word
                docx_file = create_docx(article_title, text_list)
                st.download_button(
                    label="ğŸ“„ Wordã§ä¿å­˜",
                    data=docx_file,
                    file_name="story.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    use_container_width=True 
                )
            
            with col2:
                # PDF
                pdf_file, pdf_success = create_pdf(article_title, text_list)
                
                if pdf_success:
                    st.download_button(
                        label="ğŸ“• PDFã§ä¿å­˜",
                        data=pdf_file,
                        file_name="story.pdf",
                        mime="application/pdf",
                        use_container_width=True
                    )
                else:
                    # ãƒ•ã‚©ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚
                    st.error("âš ï¸ PDFç”¨ã®ãƒ•ã‚©ãƒ³ãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦è©¦ã™ã‹ã€Wordä¿å­˜ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
            
            st.divider()
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            components.html(final_html, height=800, scrolling=True)
            
        else:
            status.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
