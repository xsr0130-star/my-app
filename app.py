import streamlit as st
import streamlit.components.v1 as components
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup, NavigableString, Tag, Comment
import time
import subprocess
import os
import re
from io import BytesIO

# Wordä½œæˆç”¨
from docx import Document
from docx.shared import RGBColor, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH

# ==========================================
# è¨­å®š
# ==========================================
FIXED_ENTRY_URL = "https://www.h-ken.net/mypage/20250611_1605697556/"

# ==========================================
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
# ==========================================
def install_playwright():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Install error: {e}")

if "setup_done" not in st.session_state:
    with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
        install_playwright()
        st.session_state.setup_done = True

# ==========================================
# è‰²è§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆCSSã‚¯ãƒ©ã‚¹å¯¾å¿œç‰ˆï¼‰
# ==========================================
def get_rgb_from_str(color_str):
    """è‰²æ–‡å­—åˆ—ã‹ã‚‰RGBColorã‚’è¿”ã™"""
    if not color_str: return None
    c = color_str.lower().strip()
    
    # Hex
    hex_match = re.search(r'#([0-9a-f]{6})', c)
    if hex_match:
        h = hex_match.group(1)
        return RGBColor(int(h[:2], 16), int(h[2:4], 16), int(h[4:], 16))
    
    # åŸºæœ¬è‰²ãƒãƒƒãƒ—
    colors = {
        'red': RGBColor(255, 0, 0),
        'blue': RGBColor(0, 0, 255),
        'green': RGBColor(0, 128, 0),
        'lightseagreen': RGBColor(32, 178, 170),
        'pink': RGBColor(255, 192, 203),
        'orange': RGBColor(255, 165, 0),
        'purple': RGBColor(128, 0, 128),
        'gray': RGBColor(128, 128, 128),
        'black': RGBColor(0, 0, 0)
    }
    return colors.get(c.split()[0]) # "red !important" å¯¾ç­–

def parse_css_colors(soup):
    """<style>ã‚¿ã‚°ã‚’è§£æã—ã¦ {ã‚¯ãƒ©ã‚¹å: RGBColor} ã®è¾æ›¸ã‚’ä½œã‚‹"""
    css_map = {}
    
    # ãƒšãƒ¼ã‚¸å†…ã®å…¨styleã‚¿ã‚°ã‚’èµ°æŸ»
    for style in soup.find_all('style'):
        if style.string:
            # æ­£è¦è¡¨ç¾ã§ .classname { color: #xxx; } ã‚’æ¢ã™
            # ç°¡æ˜“çš„ãªãƒ‘ãƒ¼ã‚¹ãªã®ã§å®Œå…¨ã§ã¯ãªã„ãŒã€ä¸»è¦ãªã‚‚ã®ã¯æ‹¾ãˆã‚‹
            matches = re.finditer(r'\.([a-zA-Z0-9_-]+)\s*\{[^}]*color\s*:\s*([^;\}]+)', style.string, re.IGNORECASE)
            for m in matches:
                class_name = m.group(1)
                color_val = m.group(2).strip()
                rgb = get_rgb_from_str(color_val)
                if rgb:
                    css_map[class_name] = rgb
                    
    # ã‚ˆãã‚ã‚‹å›ºå®šã‚¯ãƒ©ã‚¹ã‚‚è¿½åŠ ã—ã¦ãŠã
    css_map['conversation'] = RGBColor(255, 0, 0) # ä»®ã«èµ¤ã¨ã™ã‚‹ï¼ˆå¿…è¦ãªã‚‰å¤‰æ›´å¯ï¼‰
    css_map['red'] = RGBColor(255, 0, 0)
    css_map['blue'] = RGBColor(0, 0, 255)
    css_map['marker'] = RGBColor(255, 0, 0) # ãƒãƒ¼ã‚«ãƒ¼ã¯å¤§æŠµèµ¤ã‹é»„è‰²
    
    return css_map

def apply_style_to_run(run, element, css_map):
    """è¦ç´ ã®styleå±æ€§ã‚„classå±æ€§ã‚’è¦‹ã¦Wordã®Runã«è‰²ãƒ»å¤ªå­—ã‚’é©ç”¨"""
    
    # 1. å¤ªå­—åˆ¤å®š
    style_attr = element.get('style', '').lower()
    classes = element.get('class', [])
    
    if element.name in ['b', 'strong', 'h1', 'h2'] or \
       'font-weight:bold' in style_attr or 'font-weight: bold' in style_attr or \
       'bold' in classes:
        run.bold = True
        
    # 2. è‰²åˆ¤å®šï¼ˆå„ªå…ˆé †ä½: styleå±æ€§ > classå±æ€§ > fontã‚¿ã‚°ï¼‰
    rgb = None
    
    # A. style="color:..."
    if 'color' in style_attr:
        m = re.search(r'color\s*:\s*([^;"]+)', style_attr)
        if m:
            rgb = get_rgb_from_str(m.group(1))
            
    # B. class="..." (CSSãƒãƒƒãƒ—ã‹ã‚‰æ¤œç´¢)
    if not rgb and classes:
        for cls in classes:
            if cls in css_map:
                rgb = css_map[cls]
                break
                
    # C. <font color="...">
    if not rgb and element.get('color'):
        rgb = get_rgb_from_str(element.get('color'))

    if rgb:
        run.font.color.rgb = rgb

# ==========================================
# Wordä½œæˆã‚¨ãƒ³ã‚¸ãƒ³
# ==========================================
def process_node_recursive(paragraph, node, css_map):
    """å†å¸°çš„ã«ãƒãƒ¼ãƒ‰ã‚’å‡¦ç†ã—ã¦Wordã«è¿½åŠ """
    if isinstance(node, NavigableString):
        text = str(node)
        # ä¸è¦ãªã‚³ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ç­‰ãŒæ®‹ã£ã¦ã„ãªã„ã‹æœ€çµ‚ãƒã‚§ãƒƒã‚¯
        if "contents_within" not in text and text.strip():
            run = paragraph.add_run(text)
            # è¦ªã‚¿ã‚°ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ¢ã—ã¦é©ç”¨ï¼ˆç›´è¿‘ã®è¦ªã®ã¿ç°¡æ˜“é©ç”¨ï¼‰
            if node.parent:
                apply_style_to_run(run, node.parent, css_map)
                
    elif isinstance(node, Tag):
        if node.name == 'br':
            paragraph.add_run('\n')
        elif node.name in ['script', 'style', 'noscript']:
            pass # ç„¡è¦–
        else:
            # å­è¦ç´ ã‚’å†å¸°å‡¦ç†
            for child in node.children:
                process_node_recursive(paragraph, child, css_map)

def create_rich_docx(title_html, body_html, css_map):
    doc = Document()
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    soup_title = BeautifulSoup(title_html, 'html.parser')
    p_title = doc.add_paragraph()
    p_title.alignment = WD_ALIGN_PARAGRAPH.LEFT
    process_node_recursive(p_title, soup_title, css_map)
    
    # ã‚¿ã‚¤ãƒˆãƒ«å…¨ä½“ã‚’å¼·èª¿
    for run in p_title.runs:
        run.font.size = Pt(16)
        if not run.bold: run.bold = True

    doc.add_paragraph("") 

    # æœ¬æ–‡
    soup_body = BeautifulSoup(body_html, 'html.parser')
    # ãƒ–ãƒ­ãƒƒã‚¯è¦ç´ ã”ã¨ã«æ®µè½åˆ†ã‘
    blocks = soup_body.find_all(['p', 'div', 'h2', 'h3', 'blockquote'], recursive=False)
    if not blocks:
        # ãƒ«ãƒ¼ãƒˆç›´ä¸‹ã®å ´åˆ
        p = doc.add_paragraph()
        process_node_recursive(p, soup_body, css_map)
    else:
        for block in blocks:
            if block.get_text(strip=True):
                p = doc.add_paragraph()
                process_node_recursive(p, block, css_map)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œ
# ==========================================
def fetch_html_force_clean(target_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        iphone_12 = p.devices['iPhone 12']
        context = browser.new_context(**iphone_12)
        page = context.new_page()

        try:
            page.goto(FIXED_ENTRY_URL, timeout=30000)
            time.sleep(2) 
            page.goto(target_url, timeout=30000)
            page.wait_for_load_state("domcontentloaded")
            time.sleep(2) 

            # ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ç ´å£ŠJS
            page.evaluate("""
                () => {
                    const keywords = ['ã¯ã„', 'YES', 'Yes', '18æ­³', 'Enter', 'å…¥ã‚Šå£', 'å…¥å ´'];
                    const buttons = document.querySelectorAll('a, button, div, span');
                    for (let btn of buttons) {
                        if (keywords.some(k => btn.innerText && btn.innerText.includes(k))) {
                            btn.click();
                        }
                    }
                    const allDivs = document.querySelectorAll('body > div, body > section');
                    allDivs.forEach(div => {
                        const style = window.getComputedStyle(div);
                        if (style.position === 'fixed' && style.zIndex > 50) {
                            div.remove();
                        }
                    });
                    document.body.style.overflow = 'visible';
                    document.body.style.height = 'auto';
                }
            """)
            time.sleep(1) 
            return page.content()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            browser.close()

# ==========================================
# æŠ½å‡ºï¼†ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¼·åŒ–ç‰ˆï¼‰
# ==========================================
def extract_target_content(html_content, target_url):
    soup = BeautifulSoup(html_content, 'html.parser')

    # 1. CSSè§£æï¼ˆWordç”¨ï¼‰
    css_map = parse_css_colors(soup)
    
    # 2. è¡¨ç¤ºç”¨ã‚¹ã‚¿ã‚¤ãƒ«ç¢ºä¿
    styles = []
    for link in soup.find_all('link', rel='stylesheet'):
        styles.append(str(link))
    for style in soup.find_all('style'):
        styles.append(str(style))
    style_html = "\n".join(styles)

    # 3. ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
    title_html = ""
    target_h1 = soup.find("h1", class_="pageTitle")
    if target_h1:
        title_html = str(target_h1)
    else:
        target_h1 = soup.find("h1")
        if target_h1:
            title_html = str(target_h1)

    # 4. æœ¬æ–‡æŠ½å‡º
    body_html = "<div>æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>"
    
    target_div = soup.find(id="sentenceBox")
    if not target_div:
        target_div = soup.find(id="main_txt")

    if target_div:
        # --- A. HTMLã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ<!-- -->ï¼‰ã®å®Œå…¨å‰Šé™¤ ---
        for comment in target_div.find_all(string=lambda text: isinstance(text, Comment)):
            comment.extract()
            
        # --- B. ä¸è¦ã‚¿ã‚°å‰Šé™¤ ---
        for bad in target_div.find_all(["script", "noscript", "iframe", "form", "button", "input"]):
            bad.decompose()

        # --- C. æ–‡æœ«ã‚«ãƒƒãƒˆ ---
        cut_point = target_div.find(class_="kakomiPop2")
        if cut_point:
            for sibling in cut_point.find_next_siblings():
                sibling.decompose()
            cut_point.decompose()

        # --- D. è­¦å‘Šæ–‡ãƒ»ä¸è¦ãƒ†ã‚­ã‚¹ãƒˆã®å¼·åŠ›å‰Šé™¤ ---
        # å‰Šé™¤ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        bad_words = [
            "ç„¡æ–­è»¢è¼‰", "Googleã«é€šå ±", "åˆ‘äº‹å‘Šè¨´", "æ°‘äº‹è¨´è¨Ÿ", "ã‚¨ãƒã‚±ãƒ³", 
            "contents_within", "!--"
        ]
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€è¦ç´ ã‚’æ¢ã—ã¦å‰Šé™¤
        # ç¯„å›²ã‚’åºƒã’ã¦ p, div, span, font ãªã©ã‚’è¦‹ã‚‹
        for tag in target_div.find_all(['p', 'div', 'span', 'font', 'b']):
            text = tag.get_text()
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¦ã€ã‹ã¤æœ¬æ–‡ï¼ˆé•·æ–‡ï¼‰ã§ã¯ãªã„å ´åˆ
            if any(w in text for w in bad_words):
                if len(text) < 400: # 400æ–‡å­—ä»¥ä¸‹ã®è­¦å‘Šãƒ–ãƒ­ãƒƒã‚¯ãªã‚‰å‰Šé™¤
                    tag.decompose()

        body_html = str(target_div)

    # HTMLãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    final_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <base href="{target_url}">
        {style_html}
        <style>
            body {{
                background-color: #fff;
                padding: 15px;
                font-family: sans-serif;
                overflow: auto !important;
            }}
            h1.pageTitle {{
                font-size: 20px;
                margin-bottom: 20px;
                border-bottom: 1px solid #ccc;
                padding-bottom: 10px;
                line-height: 1.4;
            }}
            #sentenceBox {{
                font-size: 16px;
                line-height: 1.8;
                color: #333;
            }}
        </style>
    </head>
    <body>
        {title_html}
        {body_html}
    </body>
    </html>
    """

    return title_html, body_html, final_html, css_map

# ==========================================
# ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="H-Review Final", layout="centered")

st.title("ğŸ’ å®Œæˆç‰ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º")
st.caption("è­¦å‘Šæ–‡å‰Šé™¤ãƒ»è‰²ä»˜ãWordä¿å­˜å¯¾å¿œ")

url = st.text_input("èª­ã¿ãŸã„è¨˜äº‹ã®URL", placeholder="https://...")

if st.button("æŠ½å‡ºã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status = st.empty()
        status.info("â³ è§£æä¸­...")
        
        html = fetch_html_force_clean(url)

        if html:
            status.info("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            
            # æŠ½å‡ºï¼ˆcss_mapã‚‚å—ã‘å–ã‚‹ï¼‰
            title_html_str, body_html_str, final_html_preview, css_map = extract_target_content(html, url)
            
            status.empty()
            st.success("å®Œäº†ï¼")
            
            # è‰²ä»˜ãWordã‚’ä½œæˆï¼ˆcss_mapã‚’æ¸¡ã™ï¼‰
            docx_file = create_rich_docx(title_html_str, body_html_str, css_map)
            
            st.download_button(
                label="ğŸ“˜ Word(.docx) ã§ä¿å­˜",
                data=docx_file,
                file_name="story_colored.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True
            )
            
            st.divider()
            components.html(final_html_preview, height=800, scrolling=True)
            
        else:
            status.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
