import streamlit as st
import streamlit.components.v1 as components
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup, NavigableString, Tag, Comment
import time
import subprocess
import os
import re
from io import BytesIO

# Wordä½œæˆç”¨
from docx import Document
from docx.shared import RGBColor, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH

# ==========================================
# è¨­å®š
# ==========================================
FIXED_ENTRY_URL = "https://www.h-ken.net/mypage/20250611_1605697556/"

# ==========================================
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
# ==========================================
def install_playwright():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Install error: {e}")

if "setup_done" not in st.session_state:
    with st.spinner("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­..."):
        install_playwright()
        st.session_state.setup_done = True

# ==========================================
# ä¾¿åˆ©é–¢æ•°ï¼šãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ==========================================
def sanitize_filename(text):
    if not text: return "story"
    text = re.sub(r'[\\/*?:"<>|]', "", text)
    text = text.replace('\n', '').replace('\r', '').replace('\t', '').strip()
    if len(text) > 60: text = text[:60]
    return text if text else "story"

# ==========================================
# è‰²è§£æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶è¨ˆç®—å€¤åˆ©ç”¨ï¼‰
# ==========================================
def get_rgb_from_str(color_str):
    if not color_str: return None
    c = color_str.lower().strip()
    rgb_match = re.search(r'rgba?\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)', c)
    if rgb_match:
        return RGBColor(int(rgb_match.group(1)), int(rgb_match.group(2)), int(rgb_match.group(3)))
    hex_match = re.search(r'#([0-9a-f]{6})', c)
    if hex_match:
        h = hex_match.group(1)
        return RGBColor(int(h[:2], 16), int(h[2:4], 16), int(h[4:], 16))
    colors = {
        'red': RGBColor(255, 0, 0), 'blue': RGBColor(0, 0, 255), 'green': RGBColor(0, 128, 0),
        'black': RGBColor(0, 0, 0), 'white': RGBColor(255, 255, 255),
        'orange': RGBColor(255, 165, 0), 'pink': RGBColor(255, 192, 203),
        'purple': RGBColor(128, 0, 128), 'gold': RGBColor(255, 215, 0)
    }
    return colors.get(c.split()[0])

def apply_style_to_run(run, element):
    calc_color = element.get('data-calc-color')
    calc_bold = element.get('data-calc-bold')
    
    if calc_bold == 'true': run.bold = True
    elif element.name in ['b', 'strong', 'h1', 'h2']: run.bold = True
        
    if calc_color:
        rgb = get_rgb_from_str(calc_color)
        if rgb:
            run.font.color.rgb = rgb
            return

    style_attr = element.get('style', '').lower()
    if 'color' in style_attr:
        m = re.search(r'color\s*:\s*([^;"]+)', style_attr)
        if m: 
            rgb = get_rgb_from_str(m.group(1))
            if rgb: run.font.color.rgb = rgb

# ==========================================
# Wordä½œæˆã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆå†å¸°ãƒ»ç©ºç™½è¡Œå¯¾å¿œï¼‰
# ==========================================
BLOCK_TAGS = ['p', 'div', 'h1', 'h2', 'h3', 'blockquote', 'li', 'article', 'section']

def process_node_recursive(paragraph, node):
    if isinstance(node, NavigableString):
        text = str(node)
        if text.strip():
            run = paragraph.add_run(text)
            if node.parent: apply_style_to_run(run, node.parent)
                
    elif isinstance(node, Tag):
        if node.name == 'br':
            paragraph.add_run('\n')
        elif node.name in ['script', 'style', 'noscript']:
            pass
        else:
            for child in node.children:
                process_node_recursive(paragraph, child)
            if node.name in BLOCK_TAGS:
                paragraph.add_run('\n')

def create_rich_docx(title_html, body_html):
    doc = Document()
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    soup_title = BeautifulSoup(title_html, 'html.parser')
    p_title = doc.add_paragraph()
    p_title.alignment = WD_ALIGN_PARAGRAPH.LEFT
    process_node_recursive(p_title, soup_title)
    
    for run in p_title.runs:
        run.font.size = Pt(16)
        if not run.bold: run.bold = True

    doc.add_paragraph("") 

    # æœ¬æ–‡
    soup_body = BeautifulSoup(body_html, 'html.parser')
    
    # ã€å¤‰æ›´ç‚¹ã€‘childrenã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦ã€ãƒãƒ¼ã‚«ãƒ¼ãŒã‚ã‚Œã°ç©ºæ®µè½ã‚’è¿½åŠ 
    # ã“ã‚Œã«ã‚ˆã‚Šã€è­¦å‘Šæ–‡ãŒã‚ã£ãŸå ´æ‰€ã«ã€Œç©ºç™½è¡Œã€ãŒç”Ÿã¾ã‚Œã‚‹
    for element in soup_body.children:
        if isinstance(element, Tag):
            # ç©ºç™½è¡Œãƒãƒ¼ã‚«ãƒ¼ã®åˆ¤å®š
            if 'doc-blank-line' in element.get('class', []):
                doc.add_paragraph("") # ç©ºç™½è¡Œã‚’è¿½åŠ 
                continue
            
            # é€šå¸¸ã®è¦ç´ 
            p = doc.add_paragraph()
            process_node_recursive(p, element)
            
            # æ®µè½å†…ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã€ã‹ã¤ç”»åƒç­‰ã‚‚ãªã„å ´åˆã¯æ®µè½å‰Šé™¤ã—ã¦ã‚‚ã„ã„ãŒã€
            # æ”¹è¡Œç¶­æŒã®ãŸã‚æ®‹ã™ã®ãŒç„¡é›£
            
        elif isinstance(element, NavigableString):
            text = str(element).strip()
            if text:
                p = doc.add_paragraph()
                p.add_run(text)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œ
# ==========================================
def fetch_html_force_clean(target_url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu']
        )
        iphone_12 = p.devices['iPhone 12']
        context = browser.new_context(**iphone_12)
        page = context.new_page()

        try:
            page.goto(FIXED_ENTRY_URL, timeout=30000)
            time.sleep(2) 
            page.goto(target_url, timeout=30000)
            page.wait_for_load_state("domcontentloaded")
            time.sleep(2) 

            page.evaluate("""
                () => {
                    const keywords = ['ã¯ã„', 'YES', 'Yes', '18æ­³', 'Enter', 'å…¥ã‚Šå£', 'å…¥å ´'];
                    const buttons = document.querySelectorAll('a, button, div, span');
                    for (let btn of buttons) {
                        if (keywords.some(k => btn.innerText && btn.innerText.includes(k))) {
                            btn.click();
                        }
                    }
                    const allDivs = document.querySelectorAll('body > div, body > section');
                    allDivs.forEach(div => {
                        const style = window.getComputedStyle(div);
                        if (style.position === 'fixed' && style.zIndex > 50) {
                            div.remove();
                        }
                    });
                    document.body.style.overflow = 'visible';
                    document.body.style.height = 'auto';
                    
                    const targetArea = document.getElementById('sentenceBox') || document.body;
                    const allElements = targetArea.querySelectorAll('*');
                    allElements.forEach(el => {
                        const style = window.getComputedStyle(el);
                        const color = style.color;
                        const weight = style.fontWeight;
                        if (color && color !== 'rgb(0, 0, 0)') {
                            el.setAttribute('data-calc-color', color);
                        }
                        if (weight === 'bold' || parseInt(weight) >= 700) {
                            el.setAttribute('data-calc-bold', 'true');
                        }
                    });
                }
            """)
            time.sleep(1) 
            return page.content()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        finally:
            browser.close()

# ==========================================
# æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒãƒ¼ã‚«ãƒ¼ç½®æ›æ©Ÿèƒ½ä»˜ãï¼‰
# ==========================================
def extract_target_content(html_content, target_url):
    soup = BeautifulSoup(html_content, 'html.parser')

    styles = []
    for link in soup.find_all('link', rel='stylesheet'):
        styles.append(str(link))
    for style in soup.find_all('style'):
        styles.append(str(style))
    style_html = "\n".join(styles)

    title_html = ""
    title_text_clean = "ç„¡é¡Œ"
    target_h1 = soup.find("h1", class_="pageTitle")
    if target_h1:
        title_html = str(target_h1)
        title_text_clean = target_h1.get_text(strip=True)
    else:
        target_h1 = soup.find("h1")
        if target_h1:
            title_html = str(target_h1)
            title_text_clean = target_h1.get_text(strip=True)
    if title_text_clean == "ç„¡é¡Œ" and soup.title:
        title_text_clean = soup.title.get_text(strip=True)

    body_html = "<div>æœ¬æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ</div>"
    target_div = soup.find(id="sentenceBox")
    if not target_div:
        target_div = soup.find(id="main_txt")

    if target_div:
        # ã€é‡è¦ã€‘è­¦å‘Šæ–‡ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã€Œé€æ˜ãªç©ºç™½è¡Œãƒãƒ¼ã‚«ãƒ¼ã€ã«ç½®æ›ã™ã‚‹
        
        # 1. HTMLã‚³ãƒ¡ãƒ³ãƒˆã®å‡¦ç†
        for comment in target_div.find_all(string=lambda text: isinstance(text, Comment)):
            # è­¦å‘Šæ–‡ã£ã½ã„ã‚³ãƒ¡ãƒ³ãƒˆãªã‚‰ãƒãƒ¼ã‚«ãƒ¼ã«ç½®æ›
            c_text = str(comment)
            if "contents_within" in c_text or "ã‚¨ãƒã‚±ãƒ³" in c_text:
                new_tag = soup.new_tag("div", **{"class": "doc-blank-line"})
                comment.replace_with(new_tag)
            else:
                comment.extract() # ãã‚Œä»¥å¤–ã¯ãŸã æ¶ˆã™

        # 2. ä¸è¦ã‚¿ã‚°å‰Šé™¤
        for bad in target_div.find_all(["script", "noscript", "iframe", "form", "button", "input"]):
            bad.decompose()

        # 3. æ–‡æœ«ã‚«ãƒƒãƒˆ
        cut_point = target_div.find(class_="kakomiPop2")
        if cut_point:
            for sibling in cut_point.find_next_siblings():
                sibling.decompose()
            cut_point.decompose()

        # 4. è­¦å‘Šæ–‡ã‚¿ã‚°ã®å‡¦ç†
        bad_words = ["ç„¡æ–­è»¢è¼‰", "Googleã«é€šå ±", "åˆ‘äº‹å‘Šè¨´", "æ°‘äº‹è¨´è¨Ÿ", "ã‚¨ãƒã‚±ãƒ³"]
        for tag in target_div.find_all(['p', 'div', 'span', 'font', 'b']):
            text = tag.get_text()
            if any(w in text for w in bad_words):
                if len(text) < 400:
                    # ãŸã æ¶ˆã™ã®ã§ã¯ãªãã€ç©ºç™½è¡Œãƒãƒ¼ã‚«ãƒ¼ã«ç½®ãæ›ãˆã‚‹
                    new_tag = soup.new_tag("div", **{"class": "doc-blank-line"})
                    tag.replace_with(new_tag)

        body_html = str(target_div)

    final_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <base href="{target_url}">
        {style_html}
        <style>
            body {{ background-color: #fff; padding: 15px; font-family: sans-serif; overflow: auto !important; }}
            h1.pageTitle {{ font-size: 20px; margin-bottom: 20px; border-bottom: 1px solid #ccc; padding-bottom: 10px; line-height: 1.4; }}
            #sentenceBox {{ font-size: 16px; line-height: 1.8; color: #333; }}
            /* ã‚¢ãƒ—ãƒªä¸Šã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã¯ãƒãƒ¼ã‚«ãƒ¼ã¯è¦‹ãˆãªãã¦è‰¯ã„ï¼ˆã‚ã‚‹ã„ã¯å°‘ã—ä½™ç™½ã‚’å–ã‚‹ï¼‰ */
            .doc-blank-line {{ height: 1em; }}
        </style>
    </head>
    <body>
        {title_html}
        {body_html}
    </body>
    </html>
    """

    return title_html, body_html, final_html, title_text_clean

# ==========================================
# ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="H-Review Ultra", layout="centered")

st.title("ğŸ’ ç©¶æ¥µç‰ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º")
st.caption("å…¨è‰²å¯¾å¿œãƒ»ç©ºç™½è¡Œç¶­æŒãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åè‡ªå‹•åŒ–")

url = st.text_input("èª­ã¿ãŸã„è¨˜äº‹ã®URL", placeholder="https://...")

if st.button("æŠ½å‡ºã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        status = st.empty()
        status.info("â³ è§£æä¸­...")
        
        html = fetch_html_force_clean(url)

        if html:
            status.info("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            
            title_html_str, body_html_str, final_html_preview, title_text_clean = extract_target_content(html, url)
            
            status.empty()
            st.success("å®Œäº†ï¼")
            
            # Wordä½œæˆ
            docx_file = create_rich_docx(title_html_str, body_html_str)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
            safe_filename = sanitize_filename(title_text_clean) + ".docx"
            
            st.download_button(
                label=f"ğŸ“˜ ã€Œ{safe_filename}ã€ã§ä¿å­˜",
                data=docx_file,
                file_name=safe_filename,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True
            )
            
            st.divider()
            components.html(final_html_preview, height=800, scrolling=True)
            
        else:
            status.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
